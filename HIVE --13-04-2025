Import

sqoop import --connect jdbc:mysql://localhost/udb --username root --password cloudera --table  utab --m 1 --target-dir /user/cloudera/datadir


Export

sqoop export --connect jdbc:mysql://localhost/udb --username root --password cloudera --table  utab --m 1 --export-dir /user/cloudera/datadir


hadoop dfsadmin -safemode leave

cd
echo 1,zeyo,40 > zfile
echo 2,ravi,70 >> zfile
echo 3,rani,70 >> zfile

hive        --> type and enter

drop database if exists zdb cascade;

create database if not exists zdb;

use zdb;

create table ztab(id int,name string,amt int) row format delimited fields terminated by ',';

load data local inpath '/home/cloudera/zfile'  into table ztab;

select * from ztab;

select * from ztab where id>1;

======================
ğŸ”´QUIT FROM HIVE
======================
quit;

======================
ğŸ”´ VALIDATE WAREHOUSE DATA
======================

hadoop    fs   -ls    /user/hive/warehouse/zdb.db/ztab





LOCATION TASK============================================


hadoop dfsadmin -safemode leave

cd
echo 1,zeyo,40 > zfile
echo 2,ravi,70 >> zfile
echo 3,rani,70 >> zfile


hadoop  fs   -mkdir  /user/cloudera/ddir

hadoop  fs   -put   /home/cloudera/zfile  /user/cloudera/ddir/



ğŸ”´ Hive
======================

hive   -- type and enter

drop database if exists ldb cascade;

create database if not exists ldb;

use ldb;

create table ltab(id int,name string,amt int) row format delimited fields terminated by ',' location '/user/cloudera/ddir';

select * from ltab;

select * from ltab where id > 1;

quit;
